name: Sentence Level Transcription

on:
  workflow_run:
    workflows: ["Transcript"]
    types:
      - completed
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - 'Visuals/**'
      - 'Trans/**'

permissions:
  contents: write

jobs:
  generate-transcription:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name != 'workflow_run' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Generate sentence-level transcription
        run: |
          python3 << 'EOF'
          import json
          import os
          import re
          from datetime import datetime
          from difflib import SequenceMatcher

          def clean_text(text):
              """Remove punctuation and normalize text for matching."""
              text = re.sub(r"[^\w\s]", '', text.lower())
              contractions = {
                  "dont": "do not", "cant": "cannot", "hes": "he is", 
                  "im": "i am", "youre": "you are", "theyre": "they are",
                  "wont": "will not", "didnt": "did not", "isnt": "is not",
                  "arent": "are not", "wasnt": "was not", "werent": "were not",
                  "havent": "have not", "hasnt": "has not", "hadnt": "had not",
                  "wouldnt": "would not", "shouldnt": "should not", "couldnt": "could not"
              }
              words = text.split()
              return " ".join([contractions.get(w, w) for w in words])

          def get_similarity(a, b):
              """Calculate similarity ratio between two texts."""
              return SequenceMatcher(None, clean_text(a), clean_text(b)).ratio()

          def find_word_timestamps(sentence, segments):
              """
              Find start and end timestamps by matching sentence words 
              against word-level timestamps in segments.
              """
              sentence_words = clean_text(sentence).split()
              if not sentence_words:
                  return None, None
              
              # Build flat list of all words with timestamps
              all_words = []
              for seg in segments:
                  if "words" in seg:
                      for word_obj in seg["words"]:
                          all_words.append({
                              "word": clean_text(word_obj["word"]),
                              "start": word_obj["start"],
                              "end": word_obj["end"]
                          })
              
              if not all_words:
                  return None, None
              
              # Find best matching sequence
              best_match_start = None
              best_match_end = None
              best_score = 0
              
              # Sliding window approach
              for i in range(len(all_words) - len(sentence_words) + 1):
                  window_words = [all_words[j]["word"] for j in range(i, min(i + len(sentence_words) + 5, len(all_words)))]
                  window_text = " ".join(window_words)
                  sentence_text = " ".join(sentence_words)
                  
                  score = get_similarity(sentence_text, window_text)
                  
                  if score > best_score:
                      best_score = score
                      # Find exact word boundaries
                      matched_indices = []
                      word_idx = 0
                      
                      for j in range(i, min(i + len(sentence_words) + 5, len(all_words))):
                          if word_idx < len(sentence_words):
                              if get_similarity(sentence_words[word_idx], all_words[j]["word"]) > 0.7:
                                  matched_indices.append(j)
                                  word_idx += 1
                              if word_idx >= len(sentence_words):
                                  break
                      
                      if matched_indices:
                          best_match_start = all_words[matched_indices[0]]["start"]
                          best_match_end = all_words[matched_indices[-1]]["end"]
              
              # Return timestamps if match quality is good enough
              if best_score > 0.6:  # Threshold for acceptable match
                  return best_match_start, best_match_end
              
              return None, None

          def main():
              trans_path = "Trans/transcription.json"
              visuals_path = "Visuals/visuals.json"
              
              if not os.path.exists(trans_path) or not os.path.exists(visuals_path):
                  print("Missing source files")
                  return

              with open(trans_path, 'r', encoding='utf-8') as f:
                  trans_data = json.load(f)
              with open(visuals_path, 'r', encoding='utf-8') as f:
                  visuals = json.load(f)

              segments = trans_data.get("segments", [])
              results = []
              last_end_time = 0

              for item in visuals:
                  sentence = item["sentence"]
                  
                  # Try to find word-level timestamps
                  start_time, end_time = find_word_timestamps(sentence, segments)
                  
                  if start_time is not None and end_time is not None:
                      # Valid match found
                      results.append({
                          "id": f"i{item['number']}",
                          "number": item["number"],
                          "sentence": sentence,
                          "start": round(start_time, 3),
                          "end": round(end_time, 3),
                          "duration": round(end_time - start_time, 3)
                      })
                      last_end_time = end_time
                  else:
                      # No match found - this might be a visual-only sentence
                      # Place it slightly after the last known timestamp
                      ghost_start = round(last_end_time + 0.01, 3)
                      ghost_end = round(ghost_start + 0.5, 3)
                      results.append({
                          "id": f"i{item['number']}",
                          "number": item["number"],
                          "sentence": sentence,
                          "start": ghost_start,
                          "end": ghost_end,
                          "duration": 0.5
                      })
                      last_end_time = ghost_end

              output = {
                  "metadata": {
                      "created_at": datetime.utcnow().isoformat() + "Z",
                      "total_sentences": len(results),
                      "source_files": {
                          "visuals": visuals_path,
                          "transcription": trans_path
                      }
                  },
                  "sentence_transcriptions": results
              }

              os.makedirs("Edits", exist_ok=True)
              with open("Edits/edit.json", "w", encoding="utf-8") as f:
                  json.dump(output, f, indent=2, ensure_ascii=False)
              
              print(f"âœ… Successfully generated {len(results)} sentence transcriptions")

          if __name__ == "__main__":
              main()
          EOF

      - name: Configure Git
        run: |
          git config --global user.name "intellectra9"
          git config --global user.email "intellectra9@outlook.com"

      - name: Commit and push transcription file
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          git stash --include-untracked
          git pull origin main --rebase || echo "No rebase needed"
          git stash pop || true
          git add Edits/edit.json
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")
          git commit -m "ðŸ”„ Word-Level Timestamp Sync: ${timestamp}" || echo "No changes"
          git push https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git HEAD:main

