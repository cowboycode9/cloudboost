name: Generate Video (Animated)

on:
  workflow_dispatch:

permissions:
  contents: write

jobs:
  generate-video:
    runs-on: ubuntu-latest

    steps:  
      - name: Checkout repository  
        uses: actions/checkout@v4  

      - name: Set up Python  
        uses: actions/setup-python@v5  
        with:  
          python-version: '3.11'  

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Install Python dependencies  
        run: |  
          pip install requests pillow

      - name: Create animated video generation script
        run: |
          cat > generate_video.py << 'EOF'
          import os  
          import json  
          import subprocess
          import sys
          from PIL import Image
          import tempfile
          import shutil
          from concurrent.futures import ThreadPoolExecutor
          import time

          # === Config ===  
          AUDIO_FILE = "Audio/a1.mp3"
          EDIT_JSON = "Edits/edit.json"
          IMAGES_DIR = "Images"
          OUTPUT_DIR = "Video"
          OUTPUT_FILE = "final_video.mp4"
          TEMP_DIR = "temp_video_generation"

          # Create necessary directories
          os.makedirs(OUTPUT_DIR, exist_ok=True)
          os.makedirs(TEMP_DIR, exist_ok=True)

          start_time = time.time()
          print("ğŸ¬ Starting animated video generation with Ken Burns effect...")

          # === Validate required files ===
          required_files = [AUDIO_FILE, EDIT_JSON]
          for file_path in required_files:
              if not os.path.exists(file_path):
                  print(f"âŒ Required file not found: {file_path}")
                  sys.exit(1)

          if not os.path.exists(IMAGES_DIR):
              print(f"âŒ Images directory not found: {IMAGES_DIR}")
              sys.exit(1)

          # === Load and validate edit.json ===
          try:
              with open(EDIT_JSON, "r") as f:
                  edit_data = json.load(f)
          except json.JSONDecodeError as e:
              print(f"âŒ Invalid JSON format in {EDIT_JSON}: {e}")
              sys.exit(1)

          sentence_transcriptions = edit_data.get("sentence_transcriptions", [])
          if not sentence_transcriptions:
              print("âŒ No sentence transcriptions found")
              sys.exit(1)

          print(f"ğŸ“ Found {len(sentence_transcriptions)} segments")

          # === Get audio duration ===
          try:
              duration_cmd = [
                  "ffprobe", "-v", "quiet", "-show_entries", "format=duration", 
                  "-of", "csv=p=0", AUDIO_FILE
              ]
              result = subprocess.run(duration_cmd, capture_output=True, text=True, check=True)
              total_duration = float(result.stdout.strip())
              print(f"ğŸ“Š Audio duration: {total_duration:.2f} seconds")
          except Exception as e:
              print(f"âŒ Error getting audio duration: {e}")
              sys.exit(1)

          # === Animation function ===
          def create_animated_segment(image_path, duration, segment_id, index):
              frames = int(duration * 30)  # 30fps
              segment_output = os.path.join(TEMP_DIR, f"animated_{segment_id}.mp4")
              
              # Alternate: Even index = Pan Down, Odd index = Pan Up
              if index % 2 == 0:
                  # Pan Down: y moves from 0 to (ih-oh)
                  zoom_filter = f"zoompan=z='1.2':d={frames}:x='iw/2-(iw/zoom/2)':y='(ih-oh)*on/{frames}':s=1920x1080:fps=30"
                  direction = "â¬‡ï¸ Pan Down"
              else:
                  # Pan Up: y moves from (ih-oh) to 0
                  zoom_filter = f"zoompan=z='1.2':d={frames}:x='iw/2-(iw/zoom/2)':y='(ih-oh)*(1-on/{frames})':s=1920x1080:fps=30"
                  direction = "â¬†ï¸ Pan Up"
              
              cmd = [
                  "ffmpeg", "-y", "-loop", "1", "-i", image_path,
                  "-vf", f"{zoom_filter},format=yuv420p",
                  "-t", str(duration),
                  "-c:v", "libx264", "-preset", "fast", "-crf", "23",
                  "-pix_fmt", "yuv420p", "-an",
                  segment_output
              ]
              
              try:
                  subprocess.run(cmd, capture_output=True, text=True, check=True)
                  print(f"  âœ… {segment_id}: {direction} ({duration:.2f}s)")
                  return segment_output
              except subprocess.CalledProcessError as e:
                  print(f"  âŒ Animation failed for {segment_id}: {e.stderr}")
                  return None

          # === Process images and create animated segments ===
          def process_and_animate_image(segment_data):
              i, segment = segment_data
              segment_id = segment.get("id", f"i{i+1}")
              start_time = segment.get("start", 0)
              end_time = segment.get("end", 0)
              duration = end_time - start_time

              if duration <= 0: return None, f"Invalid duration for {segment_id}"

              image_path = os.path.join(IMAGES_DIR, f"{segment_id}.png")
              if not os.path.exists(image_path): return None, f"Image not found: {segment_id}.png"

              try:
                  with Image.open(image_path) as img:
                      if img.mode != 'RGB': img = img.convert('RGB')
                      # FORCE RESIZE to 1920x1080 to fix white background issue
                      new_img = img.resize((1920, 1080), Image.Resampling.LANCZOS)
                      processed_path = os.path.join(TEMP_DIR, f"processed_{segment_id}.png")
                      new_img.save(processed_path, "PNG", optimize=True)

                  return {
                      "id": segment_id,
                      "video_path": create_animated_segment(processed_path, duration, segment_id, i),
                      "start": start_time,
                      "end": end_time,
                      "duration": duration
                  }, None
              except Exception as e:
                  return None, f"Error processing {segment_id}: {e}"

          # Process in parallel
          print("ğŸ¨ Creating animated segments...")
          with ThreadPoolExecutor(max_workers=4) as executor:
              results = list(executor.map(process_and_animate_image, enumerate(sentence_transcriptions)))

          valid_segments = [r for r, e in results if r and r["video_path"]]
          valid_segments.sort(key=lambda x: x["start"])

          if not valid_segments:
              print("âŒ No valid segments found")
              sys.exit(1)

          # === Fill gaps between segments ===
          print("ğŸ”§ Checking for gaps...")
          for i, segment in enumerate(valid_segments):
              if i < len(valid_segments) - 1:
                  gap_end = valid_segments[i + 1]["start"]
                  if gap_end > segment["end"] + 0.1:
                      segment["duration"] = gap_end - segment["start"]
                      segment["end"] = gap_end
                      # Re-render extended segment
                      img_path = os.path.join(TEMP_DIR, f"processed_{segment['id']}.png")
                      segment["video_path"] = create_animated_segment(img_path, segment["duration"], f"{segment['id']}_ext", i)
                      print(f"ğŸ”— Extended {segment['id']} to fill gap")

          # Extend last segment
          last = valid_segments[-1]
          if last["end"] < total_duration:
              last["duration"] = total_duration - last["start"]
              img_path = os.path.join(TEMP_DIR, f"processed_{last['id']}.png")
              last["video_path"] = create_animated_segment(img_path, last["duration"], f"{last['id']}_final", len(valid_segments)-1)
              print(f"ğŸ”š Extended last segment to audio end")

          # === Concatenate ===
          print("ğŸ¥ Concatenating...")
          segments_file = os.path.join(TEMP_DIR, "segments.txt")
          with open(segments_file, "w") as f:
              for s in valid_segments:
                  f.write(f"file '{os.path.abspath(s['video_path'])}'\n")

          concat_cmd = [
              "ffmpeg", "-y", "-f", "concat", "-safe", "0",
              "-i", segments_file, "-i", AUDIO_FILE,
              "-c:v", "copy", "-c:a", "aac", "-b:a", "192k",
              "-shortest", "-movflags", "+faststart",
              os.path.join(OUTPUT_DIR, OUTPUT_FILE)
          ]
          
          try:
              subprocess.run(concat_cmd, capture_output=True, text=True, check=True)
              print(f"âœ… Success! Output: {os.path.join(OUTPUT_DIR, OUTPUT_FILE)}")
          except subprocess.CalledProcessError as e:
              print(f"âŒ Concatenation failed: {e.stderr}")
              sys.exit(1)
          
          EOF

      - name: Run animated video generation
        run: python3 generate_video.py

      - name: Configure Git  
        run: |  
          git config --global user.name "intellect9"  
          git config --global user.email "intellectra9@outlook.com"  

      - name: Commit and push generated video  
        env:  
          GH_PAT: ${{ secrets.GH_PAT }}  
        run: |  
          git stash --include-untracked  
          git pull origin main --rebase || echo "No rebase needed"  
          git stash pop || true  

          git add Video/  
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")
          git commit -m "ğŸ¬ Generated animated video - Ken Burns: ${timestamp}" || echo "No changes to commit"  

          git remote set-url origin "https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git"
          git push origin HEAD:main
          exit 0
