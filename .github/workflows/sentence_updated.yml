name: Sentence Level Transcription

on:
  workflow_run:
    workflows: ["Transcript"]
    types:
      - completed
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - 'Visuals/**'
      - 'Trans/**'

permissions:
  contents: write

jobs:
  generate-transcription:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name != 'workflow_run' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Generate sentence-level transcription
        run: |
          python3 << 'EOF'
          import json
          import os
          import re
          from datetime import datetime
          from difflib import SequenceMatcher

          def clean(text):
              # Remove punctuation and normalize for better matching
              text = re.sub(r"[^\w\s]", '', text.lower())
              contractions = {"dont": "do not", "cant": "cannot", "hes": "he is", "im": "i am", "youre": "you are", "theyre": "they are"}
              words = text.split()
              return " ".join([contractions.get(w, w) for w in words])

          def get_similarity(a, b):
              return SequenceMatcher(None, clean(a), clean(b)).ratio()

          def main():
              trans_path = "Trans/transcription.json"
              visuals_path = "Visuals/visuals.json"
              
              if not os.path.exists(trans_path) or not os.path.exists(visuals_path):
                  print("Missing source files")
                  return

              with open(trans_path, 'r') as f:
                  trans_data = json.load(f)
              with open(visuals_path, 'r') as f:
                  visuals = json.load(f)

              segments = trans_data.get("segments", [])
              results = []
              last_seg_idx = 0

              for item in visuals:
                  target_text = item["sentence"]
                  best_match = None
                  best_score = 0.45  # Flexible threshold for "ghost" sentences
                  
                  # Look ahead 20 segments to find the next spoken line
                  search_limit = min(last_seg_idx + 20, len(segments))
                  for i in range(last_seg_idx, search_limit):
                      score = get_similarity(target_text, segments[i]["text"])
                      if score > best_score:
                          best_score = score
                          best_match = segments[i]
                          last_seg_idx = i # Update anchor to current best match

                  if best_match:
                      results.append({
                          "id": f"i{item['number']}",
                          "number": item["number"],
                          "sentence": target_text,
                          "start": round(best_match["start"], 3),
                          "end": round(best_match["end"], 3),
                          "duration": round(best_match["end"] - best_match["start"], 3)
                      })
                      # FIX: Force the index to move forward by 1 to prevent matching the exact same segment twice (collision)
                      last_seg_idx += 1
                  else:
                      # If sentence is NOT in audio, place it slightly after the last match
                      prev_end = results[-1]["end"] if results else 0
                      results.append({
                          "id": f"i{item['number']}",
                          "number": item["number"],
                          "sentence": target_text,
                          "start": round(prev_end + 0.01, 3),
                          "end": round(prev_end + 0.51, 3),
                          "duration": 0.5
                      })

              output = {
                  "metadata": {
                      "created_at": datetime.utcnow().isoformat() + "Z",
                      "total_sentences": len(results),
                      "source_files": {"visuals": visuals_path, "transcription": trans_path}
                  },
                  "sentence_transcriptions": results
              }

              os.makedirs("Edits", exist_ok=True)
              with open("Edits/edit.json", "w", encoding="utf-8") as f:
                  json.dump(output, f, indent=2, ensure_ascii=False)

          if __name__ == "__main__":
              main()
          EOF

      - name: Configure Git
        run: |
          git config --global user.name "intellectra9"
          git config --global user.email "intellectra9@outlook.com"

      - name: Commit and push transcription file
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          git stash --include-untracked
          git pull origin main --rebase || echo "No rebase needed"
          git stash pop || true
          git add Edits/edit.json
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")
          git commit -m "ðŸ”„ Final Sync Fix: ${timestamp}" || echo "No changes"
          git push https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git HEAD:main
