name: Generate Video Animated

on:
  workflow_dispatch:

permissions:
  contents: write

jobs:
  generate-video:
    runs-on: ubuntu-latest

    steps:  
      - name: Checkout repository  
        uses: actions/checkout@v4  

      - name: Set up Python  
        uses: actions/setup-python@v5  
        with:  
          python-version: '3.11'  

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Install Python dependencies  
        run: |  
          pip install requests pillow

      - name: Create animated video generation script
        run: |
          cat > generate_video.py << 'EOF'
          import os  
          import json  
          import subprocess
          import sys
          from PIL import Image
          import tempfile
          import shutil
          from concurrent.futures import ThreadPoolExecutor
          import time

          # === Config ===  
          AUDIO_FILE = "Audio/a1.mp3"
          EDIT_JSON = "Edits/edit.json"
          IMAGES_DIR = "Images"
          OUTPUT_DIR = "Video"
          OUTPUT_FILE = "final_video.mp4"
          TEMP_DIR = "temp_video_generation"

          # Create necessary directories
          os.makedirs(OUTPUT_DIR, exist_ok=True)
          os.makedirs(TEMP_DIR, exist_ok=True)

          start_time = time.time()
          print("üé¨ Starting animated video generation with Ken Burns effect...")

          # === Validate required files ===
          required_files = [AUDIO_FILE, EDIT_JSON]
          for file_path in required_files:
              if not os.path.exists(file_path):
                  print(f"‚ùå Required file not found: {file_path}")
                  sys.exit(1)

          if not os.path.exists(IMAGES_DIR):
              print(f"‚ùå Images directory not found: {IMAGES_DIR}")
              sys.exit(1)

          print("‚úÖ All required files found")

          # === Load and validate edit.json ===
          try:
              with open(EDIT_JSON, "r") as f:
                  edit_data = json.load(f)
          except json.JSONDecodeError as e:
              print(f"‚ùå Invalid JSON format in {EDIT_JSON}: {e}")
              sys.exit(1)

          sentence_transcriptions = edit_data.get("sentence_transcriptions", [])
          if not sentence_transcriptions:
              print("‚ùå No sentence transcriptions found")
              sys.exit(1)

          print(f"üìù Found {len(sentence_transcriptions)} segments")

          # === Get audio duration first ===
          print("üîç Getting audio duration...")
          try:
              duration_cmd = [
                  "ffprobe", "-v", "quiet", "-show_entries", "format=duration", 
                  "-of", "csv=p=0", AUDIO_FILE
              ]
              result = subprocess.run(duration_cmd, capture_output=True, text=True, check=True)
              total_duration = float(result.stdout.strip())
              print(f"üìä Audio duration: {total_duration:.2f} seconds")
          except Exception as e:
              print(f"‚ùå Error getting audio duration: {e}")
              sys.exit(1)

          # === Animation function ===
          def create_animated_segment(image_path, duration, segment_id, index):
              """
              Create animated segment with slow vertical pan (up or down)
              Alternates between pan down and pan up for visual variety
              """
              frames = int(duration * 30)  # 30fps
              segment_output = os.path.join(TEMP_DIR, f"animated_{segment_id}.mp4")
              
              # Alternate between pan down (even index) and pan up (odd index)
              if index % 2 == 0:
                  # Pan Down: Start from top, slowly move down
                  # y moves from 0 to (ih-oh) over the duration
                  zoom_filter = f"zoompan=z='1.2':d={frames}:x='iw/2-(iw/zoom/2)':y='(ih-oh)*on/{frames}':s=1920x1080:fps=30"
                  direction = "‚¨áÔ∏è Pan Down"
              else:
                  # Pan Up: Start from bottom, slowly move up
                  # y moves from (ih-oh) to 0 over the duration
                  zoom_filter = f"zoompan=z='1.2':d={frames}:x='iw/2-(iw/zoom/2)':y='(ih-oh)*(1-on/{frames})':s=1920x1080:fps=30"
                  direction = "‚¨ÜÔ∏è Pan Up"
              
              cmd = [
                  "ffmpeg", "-y",
                  "-loop", "1",
                  "-i", image_path,
                  "-vf", f"{zoom_filter},format=yuv420p",
                  "-t", str(duration),
                  "-c:v", "libx264",
                  "-preset", "fast",
                  "-crf", "23",
                  "-pix_fmt", "yuv420p",
                  "-an",  # No audio in segments
                  segment_output
              ]
              
              try:
                  result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                  print(f"  ‚úÖ {segment_id}: {direction} ({duration:.2f}s)")
                  return segment_output
              except subprocess.CalledProcessError as e:
                  print(f"  ‚ùå Animation failed for {segment_id}: {e.stderr}")
                  return None

          # === Process images and create animated segments ===
          def process_and_animate_image(segment_data):
              i, segment = segment_data
              segment_id = segment.get("id", f"i{i+1}")
              start_time = segment.get("start", 0)
              end_time = segment.get("end", 0)
              duration = end_time - start_time

              if duration <= 0:
                  return None, f"Invalid duration for segment {segment_id}"

              image_filename = f"{segment_id}.png"
              image_path = os.path.join(IMAGES_DIR, image_filename)

              if not os.path.exists(image_path):
                  return None, f"Image not found: {image_filename}"

              try:
                  # Process image: resize to 1920x1080
                  with Image.open(image_path) as img:
                      if img.mode != 'RGB':
                          img = img.convert('RGB')
                      
                      # Resize to exact dimensions for consistent output
                      new_img = img.resize((1920, 1080), Image.Resampling.LANCZOS)
                      
                      processed_path = os.path.join(TEMP_DIR, f"processed_{segment_id}.png")
                      new_img.save(processed_path, "PNG", optimize=True)

                  # Create animated video segment
                  animated_path = create_animated_segment(
                      processed_path, 
                      duration, 
                      segment_id,
                      i  # Pass index for alternating direction
                  )
                  
                  if not animated_path:
                      return None, f"Animation failed for {segment_id}"

                  return {
                      "id": segment_id,
                      "video_path": animated_path,
                      "start": start_time,
                      "end": end_time,
                      "duration": duration
                  }, None

              except Exception as e:
                  return None, f"Error processing {image_filename}: {e}"

          # Process images and create animations in parallel
          print("üé® Creating animated segments...")
          with ThreadPoolExecutor(max_workers=4) as executor:
              results = list(executor.map(process_and_animate_image, enumerate(sentence_transcriptions)))

          # Collect valid segments and errors
          valid_segments = []
          errors = []

          for result, error in results:
              if result:
                  valid_segments.append(result)
              if error:
                  errors.append(error)

          if errors:
              print(f"‚ö†Ô∏è Issues found: {len(errors)}")
              for error in errors[:5]:
                  print(f"  - {error}")

          if not valid_segments:
              print("‚ùå No valid segments found")
              sys.exit(1)

          # Sort by start time
          valid_segments.sort(key=lambda x: x["start"])
          print(f"‚úÖ Created {len(valid_segments)} animated segments")

          # === Fill gaps between segments ===
          print("üîß Filling gaps between segments...")

          for i, segment in enumerate(valid_segments):
              # Check if there's a gap before the next segment
              if i < len(valid_segments) - 1:
                  next_segment = valid_segments[i + 1]
                  gap_start = segment["end"]
                  gap_end = next_segment["start"]
                  
                  if gap_end > gap_start + 0.1:  # Gap larger than 0.1 seconds
                      # Extend current segment to fill the gap
                      old_duration = segment["duration"]
                      segment["end"] = gap_end
                      segment["duration"] = gap_end - segment["start"]
                      
                      # Re-render the segment with new duration
                      segment_id = segment["id"]
                      old_video_path = segment["video_path"]
                      image_path = os.path.join(TEMP_DIR, f"processed_{segment_id}.png")
                      
                      if os.path.exists(image_path):
                          new_video_path = create_animated_segment(
                              image_path,
                              segment["duration"],
                              f"{segment_id}_extended",
                              i
                          )
                          if new_video_path:
                              segment["video_path"] = new_video_path
                              # Remove old video file
                              try:
                                  os.remove(old_video_path)
                              except:
                                  pass
                              print(f"üîó Extended {segment_id}: {old_duration:.2f}s -> {segment['duration']:.2f}s")

          # Extend last segment to end of audio if needed
          if valid_segments:
              last_segment = valid_segments[-1]
              if last_segment["end"] < total_duration:
                  old_duration = last_segment["duration"]
                  last_segment["end"] = total_duration
                  last_segment["duration"] = total_duration - last_segment["start"]
                  
                  # Re-render last segment
                  segment_id = last_segment["id"]
                  old_video_path = last_segment["video_path"]
                  image_path = os.path.join(TEMP_DIR, f"processed_{segment_id}.png")
                  
                  if os.path.exists(image_path):
                      new_video_path = create_animated_segment(
                          image_path,
                          last_segment["duration"],
                          f"{segment_id}_final",
                          len(valid_segments) - 1
                      )
                      if new_video_path:
                          last_segment["video_path"] = new_video_path
                          try:
                              os.remove(old_video_path)
                          except:
                              pass
                          print(f"üîö Extended last segment: {old_duration:.2f}s -> {last_segment['duration']:.2f}s")

          # === Create final video by concatenating segments ===
          print("üé• Concatenating animated segments with audio...")

          output_path = os.path.join(OUTPUT_DIR, OUTPUT_FILE)

          # Create concatenation file
          segments_file = os.path.join(TEMP_DIR, "segments.txt")
          with open(segments_file, "w") as f:
              for segment in valid_segments:
                  # Use absolute path for safety
                  abs_path = os.path.abspath(segment["video_path"])
                  f.write(f"file '{abs_path}'\n")

          # Concatenate video segments and add audio
          concat_cmd = [
              "ffmpeg", "-y",
              "-f", "concat",
              "-safe", "0",
              "-i", segments_file,
              "-i", AUDIO_FILE,
              "-c:v", "copy",  # Copy video codec (no re-encoding)
              "-c:a", "aac",
              "-b:a", "192k",
              "-shortest",  # Match shortest stream (audio)
              "-movflags", "+faststart",
              output_path
          ]

          print("üîß Executing final FFmpeg concatenation...")
          try:
              result = subprocess.run(concat_cmd, capture_output=True, text=True, check=True)
              
              if os.path.exists(output_path):
                  file_size = os.path.getsize(output_path) / (1024*1024)
                  elapsed = time.time() - start_time
                  
                  print("\n" + "="*60)
                  print("‚úÖ VIDEO GENERATION COMPLETED SUCCESSFULLY!")
                  print("="*60)
                  print(f"üìÅ Output: {output_path}")
                  print(f"üìä Size: {file_size:.2f} MB")
                  print(f"‚è±Ô∏è Time: {elapsed:.2f} seconds")
                  print(f"üé¨ Animation: Smooth vertical panning (up/down)")
                  print(f"üîä Audio: Perfectly synced")
                  print("="*60)
              else:
                  print("‚ùå Output file not created")
                  sys.exit(1)
                  
          except subprocess.CalledProcessError as e:
              print(f"‚ùå FFmpeg concatenation failed: {e}")
              print(f"stderr: {e.stderr}")
              sys.exit(1)

          # === Cleanup temporary files ===
          print("üßπ Cleaning up temporary files...")
          try:
              shutil.rmtree(TEMP_DIR, ignore_errors=True)
              print("‚úÖ Cleanup complete")
          except Exception as e:
              print(f"‚ö†Ô∏è Cleanup warning: {e}")

          total_time = time.time() - start_time
          print(f"\nüéâ ALL DONE! Total time: {total_time:.2f} seconds")
          print("üé• Your animated video is ready with smooth Ken Burns effect!")
          EOF

      - name: Run animated video generation
        run: python3 generate_video.py

      - name: Configure Git  
        run: |  
          git config --global user.name "intellect9"  
          git config --global user.email "intellectra9@outlook.com"  

      - name: Commit and push generated video  
        env:  
          GH_PAT: ${{ secrets.GH_PAT }}  
        run: |  
          git stash --include-untracked  
          git pull origin main --rebase || echo "No rebase needed"  
          git stash pop || true  

          git add Video/  
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")  
          git commit -m "üé¨ Generated animated video (Ken Burns): ${timestamp}" || echo "No changes to commit"  

          git remote set-url origin https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git  
          git push origin HEAD:main
``` Your video is ready!
                      if img.mode != 'RGB':
                          img = img.convert('RGB')
                      
                      # --- FIX: Force Resize instead of Thumbnail ---
                      # Using resize((1920, 1080)) forces the image to fill the frame exactly.
                      # This eliminates any background borders.
                      new_img = img.resize((1920, 1080), Image.Resampling.LANCZOS)
                      
                      # Save processed image
                      processed_path = os.path.join(TEMP_DIR, f"processed_{segment_id}.png")
                      new_img.save(processed_path, "PNG", optimize=True)

                  return {
                      "id": segment_id,
                      "image_path": processed_path,
                      "start": start_time,
                      "end": end_time,
                      "duration": duration
                  }, None

              except Exception as e:
                  return None, f"Error processing {image_filename}: {e}"

          # Process images in parallel
          print("üñºÔ∏è Processing images in parallel...")
          with ThreadPoolExecutor(max_workers=4) as executor:
              results = list(executor.map(process_image, enumerate(sentence_transcriptions)))

          # Collect valid segments and errors
          valid_segments = []
          errors = []

          for result, error in results:
              if result:
                  valid_segments.append(result)
              if error:
                  errors.append(error)

          if errors:
              print(f"‚ö†Ô∏è Issues found: {len(errors)}")
              for error in errors[:5]:  # Show first 5 errors
                  print(f"  - {error}")

          if not valid_segments:
              print("‚ùå No valid segments found")
              sys.exit(1)

          # Sort by start time
          valid_segments.sort(key=lambda x: x["start"])
          print(f"‚úÖ Processed {len(valid_segments)} segments")

          # === Fill gaps between segments ===
          print("üîß Filling gaps between segments...")
          filled_segments = []
          
          for i, segment in enumerate(valid_segments):
              filled_segments.append(segment)
              
              # Check if there's a gap before the next segment
              if i < len(valid_segments) - 1:
                  next_segment = valid_segments[i + 1]
                  gap_start = segment["end"]
                  gap_end = next_segment["start"]
                  
                  if gap_end > gap_start + 0.1:  # Gap larger than 0.1 seconds
                      # Extend current segment to fill the gap
                      segment["end"] = gap_end
                      segment["duration"] = gap_end - segment["start"]
                      print(f"üîó Extended segment {segment['id']} to fill gap: {gap_start:.2f}s -> {gap_end:.2f}s")

          # Extend last segment to end of audio if needed
          if valid_segments:
              last_segment = valid_segments[-1]
              if last_segment["end"] < total_duration:
                  last_segment["end"] = total_duration
                  last_segment["duration"] = total_duration - last_segment["start"]
                  print(f"üîö Extended last segment to audio end: {last_segment['end']:.2f}s")

          # === Create seamless video ===
          print("üé• Creating seamless video...")
          
          output_path = os.path.join(OUTPUT_DIR, OUTPUT_FILE)
          
          # Build optimized FFmpeg command
          input_args = ["-i", AUDIO_FILE]
          
          # Add all images as inputs
          for segment in valid_segments:
              input_args.extend(["-loop", "1", "-i", segment["image_path"]])
          
          # Create filter complex for seamless transitions
          filter_parts = []
          
          # Scale all images to exact dimensions (Redundant safety check but good for FFmpeg)
          for i, segment in enumerate(valid_segments):
              input_idx = i + 1
              filter_parts.append(f"[{input_idx}:v]scale=1920:1080,fps=30,format=yuv420p[v{i}];")
          
          # Create timeline with no gaps
          if len(valid_segments) == 1:
              # Single segment case
              segment = valid_segments[0]
              filter_parts.append(f"[v0]trim=0:{segment['duration']},setpts=PTS-STARTPTS+{segment['start']}/TB[final];")
          else:
              # Multiple segments with seamless transitions
              concat_inputs = []
              for i, segment in enumerate(valid_segments):
                  # Create segment with exact duration
                  filter_parts.append(f"[v{i}]trim=0:{segment['duration']},setpts=PTS-STARTPTS[s{i}];")
                  concat_inputs.append(f"[s{i}]")
              
              # Concatenate all segments
              filter_parts.append(f"{''.join(concat_inputs)}concat=n={len(valid_segments)}:v=1:a=0[final];")
          
          filter_complex = "".join(filter_parts)
          
          # Build final FFmpeg command
          ffmpeg_cmd = [
              "ffmpeg", "-y",
              "-hide_banner", "-loglevel", "warning"
          ] + input_args + [
              "-filter_complex", filter_complex,
              "-map", "[final]",
              "-map", "0:a",
              "-c:v", "libx264",
              "-preset", "fast",
              "-crf", "23",
              "-c:a", "aac",
              "-b:a", "192k",
              "-pix_fmt", "yuv420p",
              "-movflags", "+faststart",
              "-t", str(total_duration),
              output_path
          ]
          
          print("üîß Executing FFmpeg...")
          try:
              result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True, check=True)
              
              if os.path.exists(output_path):
                  file_size = os.path.getsize(output_path) / (1024*1024)
                  elapsed = time.time() - start_time
                  
                  print("‚úÖ Video generation completed successfully!")
                  print(f"üìÅ Output: {output_path}")
                  print(f"üìä Size: {file_size:.2f} MB")
                  print(f"‚è±Ô∏è Time: {elapsed:.2f} seconds")
              else:
                  print("‚ùå Output file not created")
                  sys.exit(1)
                  
          except subprocess.CalledProcessError as e:
              print(f"‚ùå FFmpeg failed: {e}")
              print(f"stderr: {e.stderr}")
              
              # Fallback method with simpler approach
              print("üîÑ Trying fallback method...")
              
              # Create simple concatenation
              segments_file = os.path.join(TEMP_DIR, "segments.txt")
              with open(segments_file, "w") as f:
                  for segment in valid_segments:
                      f.write(f"file '{segment['image_path']}'\n")
                      f.write(f"duration {segment['duration']}\n")
                  # Add last image again to avoid truncation
                  if valid_segments:
                      f.write(f"file '{valid_segments[-1]['image_path']}'\n")
              
              fallback_cmd = [
                  "ffmpeg", "-y",
                  "-f", "concat",
                  "-safe", "0",
                  "-i", segments_file,
                  "-i", AUDIO_FILE,
                  "-c:v", "libx264",
                  "-preset", "fast",
                  "-crf", "23",
                  "-c:a", "aac",
                  "-b:a", "192k",
                  "-pix_fmt", "yuv420p",
                  "-shortest",
                  output_path
              ]
              
              try:
                  result = subprocess.run(fallback_cmd, capture_output=True, text=True, check=True)
                  print("‚úÖ Fallback method succeeded!")
              except subprocess.CalledProcessError as e2:
                  print(f"‚ùå Fallback method failed: {e2}")
                  sys.exit(1)

          # === Cleanup ===
          try:
              shutil.rmtree(TEMP_DIR, ignore_errors=True)
          except:
              pass
          
          total_time = time.time() - start_time
          print(f"üéâ Complete! Total time: {total_time:.2f} seconds")
          print("üîä Seamless audio-video sync achieved!")
          print("üì∫ FULL SCREEN 16:9 RATIO ENFORCED!")
          EOF

      - name: Run optimized video generation
        run: python3 generate_video.py

      - name: Configure Git  
        run: |  
          git config --global user.name "intellect9"  
          git config --global user.email "intellectra9@outlook.com"  

      - name: Commit and push generated video  
        env:  
          GH_PAT: ${{ secrets.GH_PAT }}  
        run: |  
          git stash --include-untracked  
          git pull origin main --rebase || echo "No rebase needed"  
          git stash pop || true  

          git add Video/  
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")  
          git commit -m "üé¨ Generated optimized seamless video: ${timestamp}" || echo "No changes to commit"  

          git remote set-url origin https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git  
          git push origin HEAD:main
