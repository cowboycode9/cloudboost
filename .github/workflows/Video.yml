name: Generate Video (Animated + Captions)

on:
  workflow_dispatch:

permissions:
  contents: write

jobs:
  generate-video:
    runs-on: ubuntu-latest

    steps:  
      - name: Checkout repository  
        uses: actions/checkout@v4  

      - name: Set up Python  
        uses: actions/setup-python@v5  
        with:  
          python-version: '3.11'  

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Install Python dependencies  
        run: |  
          pip install requests pillow

      - name: Create animated video generation script
        run: |
          cat > generate_video.py << 'EOF'
          import os  
          import json  
          import subprocess
          import sys
          from PIL import Image
          from concurrent.futures import ThreadPoolExecutor
          import time

          # === Config ===  
          AUDIO_FILE = "Audio/a1.mp3"
          EDIT_JSON = "Edits/edit.json"
          TRANSCRIPTION_JSON = "Trans/transcription.json"  
          IMAGES_DIR = "Images"
          OUTPUT_DIR = "Video"
          OUTPUT_FILE = "final_video.mp4"
          TEMP_DIR = "temp_video_generation"

          # Create necessary directories
          os.makedirs(OUTPUT_DIR, exist_ok=True)
          os.makedirs(TEMP_DIR, exist_ok=True)

          print("ğŸ¬ Starting video generation with Animated Captions...")

          # === Validate required files ===
          required_files = [AUDIO_FILE, EDIT_JSON, TRANSCRIPTION_JSON]
          for file_path in required_files:
              if not os.path.exists(file_path):
                  print(f"âŒ Required file not found: {file_path}")
                  sys.exit(1)

          if not os.path.exists(IMAGES_DIR):
              print(f"âŒ Images directory not found: {IMAGES_DIR}")
              sys.exit(1)

          # === Load JSON Data ===
          try:
              with open(EDIT_JSON, "r") as f:
                  edit_data = json.load(f)
              
              with open(TRANSCRIPTION_JSON, "r") as f:
                  transcription_data = json.load(f)
          except json.JSONDecodeError as e:
              print(f"âŒ Invalid JSON format: {e}")
              sys.exit(1)

          sentence_transcriptions = edit_data.get("sentence_transcriptions", [])

          # === Helper: Time Formatting for .ASS Subtitles ===
          def format_ass_time(seconds):
              hrs = int(seconds // 3600)
              mins = int((seconds % 3600) // 60)
              secs = int(seconds % 60)
              cs = int((seconds * 100) % 100)
              return f"{hrs:01d}:{mins:02d}:{secs:02d}.{cs:02d}"

          # === Function: Generate Karaoke Subtitles (.ass) ===
          def generate_subtitles(transcription_data, output_path):
              print("ğŸ“ Generating caption file...")
              
              # ASS Header
              # UPDATED STYLE: Font is now 'Arial Black', Bold is -1 (True), Outline is 4
              ass_content = """[Script Info]
          ScriptType: v4.00+
          PlayResX: 1920
          PlayResY: 1080

          [V4+ Styles]
          Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
          Style: Default,Arial Black,80,&H00FFFFFF,&H0000FFFF,&H00000000,&H80000000,-1,0,1,4,0,2,10,10,60,1

          [Events]
          Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
          """
              events = []
              
              # Use segments from transcription.json
              segments = transcription_data.get("segments", [])
              
              for segment in segments:
                  words = segment.get("words", [])
                  if not words: continue

                  # Process words in chunks of 3
                  chunk_size = 3
                  for i in range(0, len(words), chunk_size):
                      chunk = words[i : i + chunk_size]
                      
                      # Create events for highlighting each word in the chunk
                      for j in range(len(chunk)):
                          current_word_idx = j
                          state_start = chunk[j]['start']
                          
                          # Duration of this state is until the next word starts
                          if j < len(chunk) - 1:
                              state_end = chunk[j+1]['start']
                          else:
                              state_end = chunk[j]['end']
                              
                          # Build the text string for this state
                          text_parts = []
                          for k, word_obj in enumerate(chunk):
                              word_text = word_obj['word']
                              # ASS Color Tags: {\c&H00FFFF&} = Yellow, {\c&HFFFFFF&} = White
                              # We add {\b1} to ensure bold is forced on every word
                              if k <= current_word_idx:
                                  # Highlighted (Yellow)
                                  text_parts.append(f"{{\\c&H00FFFF&}}{{\\b1}}{word_text}")
                              else:
                                  # Not yet spoken (White)
                                  text_parts.append(f"{{\\c&HFFFFFF&}}{{\\b1}}{word_text}")
                          
                          full_text = " ".join(text_parts)
                          events.append(f"Dialogue: 0,{format_ass_time(state_start)},{format_ass_time(state_end)},Default,,0,0,0,,{full_text}")

              with open(output_path, "w") as f:
                  f.write(ass_content + "\n".join(events))
              
              print(f"âœ… Captions generated: {output_path}")

          # === Generate the Subtitles ===
          generate_subtitles(transcription_data, "captions.ass")

          # === Get audio duration ===
          try:
              duration_cmd = [
                  "ffprobe", "-v", "quiet", "-show_entries", "format=duration", 
                  "-of", "csv=p=0", AUDIO_FILE
              ]
              result = subprocess.run(duration_cmd, capture_output=True, text=True, check=True)
              total_duration = float(result.stdout.strip())
          except Exception as e:
              print(f"âŒ Error getting audio duration: {e}")
              sys.exit(1)

          # === Animation Logic ===
          def create_animated_segment(image_path, duration, segment_id, index):
              frames = int(duration * 30)
              segment_output = os.path.join(TEMP_DIR, f"animated_{segment_id}.mp4")
              z = 1.2
              
              if index % 2 == 0:
                  y_expr = f"'ih*(1-1/{z})*on/{frames}'" # Pan Down
              else:
                  y_expr = f"'ih*(1-1/{z})*(1-on/{frames})'" # Pan Up

              x_expr = f"'iw*(1-1/{z})/2'"
              zoom_filter = f"zoompan=z='{z}':d={frames}:x={x_expr}:y={y_expr}:s=1920x1080:fps=30"
              
              cmd = [
                  "ffmpeg", "-y", "-loop", "1", "-i", image_path,
                  "-vf", f"{zoom_filter},format=yuv420p",
                  "-t", str(duration),
                  "-c:v", "libx264", "-preset", "fast", "-crf", "23",
                  "-pix_fmt", "yuv420p", "-an", segment_output
              ]
              subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
              return segment_output

          # === Process Images ===
          def process_and_animate_image(segment_data):
              i, segment = segment_data
              segment_id = segment.get("id", f"i{i+1}")
              start_time = segment.get("start", 0)
              end_time = segment.get("end", 0)
              duration = end_time - start_time
              
              if duration <= 0: return None

              image_path = os.path.join(IMAGES_DIR, f"{segment_id}.png")
              if not os.path.exists(image_path): return None

              try:
                  with Image.open(image_path) as img:
                      if img.mode != 'RGB': img = img.convert('RGB')
                      new_img = img.resize((1920, 1080), Image.Resampling.LANCZOS)
                      processed_path = os.path.join(TEMP_DIR, f"processed_{segment_id}.png")
                      new_img.save(processed_path, "PNG", optimize=True)

                  return {
                      "id": segment_id,
                      "video_path": create_animated_segment(processed_path, duration, segment_id, i),
                      "start": start_time,
                      "end": end_time
                  }
              except Exception as e:
                  print(f"Error: {e}")
                  return None

          print("ğŸ¨ Creating animated segments...")
          with ThreadPoolExecutor(max_workers=4) as executor:
              results = list(executor.map(process_and_animate_image, enumerate(sentence_transcriptions)))

          valid_segments = [r for r in results if r and r["video_path"]]
          valid_segments.sort(key=lambda x: x["start"])

          if not valid_segments: 
              print("âŒ No valid segments found.")
              sys.exit(1)

          # === Check for gaps and extend ===
          for i, segment in enumerate(valid_segments):
              if i < len(valid_segments) - 1:
                  gap_end = valid_segments[i + 1]["start"]
                  if gap_end > segment["end"] + 0.1:
                      segment["duration"] = gap_end - segment["start"]
                      segment["end"] = gap_end
                      # Re-render extended segment
                      img_path = os.path.join(TEMP_DIR, f"processed_{segment['id']}.png")
                      segment["video_path"] = create_animated_segment(img_path, segment["duration"], f"{segment['id']}_ext", i)

          # Extend last segment
          last = valid_segments[-1]
          if last["end"] < total_duration:
              last["duration"] = total_duration - last["start"]
              img_path = os.path.join(TEMP_DIR, f"processed_{last['id']}.png")
              last["video_path"] = create_animated_segment(img_path, last["duration"], f"{last['id']}_final", len(valid_segments)-1)

          # === Concatenate and Add Subtitles ===
          print("ğŸ¥ Concatenating and burning captions...")
          segments_file = os.path.join(TEMP_DIR, "segments.txt")
          with open(segments_file, "w") as f:
              for s in valid_segments:
                  f.write(f"file '{os.path.abspath(s['video_path'])}'\n")

          concat_cmd = [
              "ffmpeg", "-y", "-f", "concat", "-safe", "0",
              "-i", segments_file, "-i", AUDIO_FILE,
              "-vf", "subtitles=captions.ass",
              "-c:v", "libx264", "-c:a", "aac", "-b:a", "192k",
              "-shortest", "-movflags", "+faststart",
              os.path.join(OUTPUT_DIR, OUTPUT_FILE)
          ]
          
          try:
              subprocess.run(concat_cmd, check=True, stderr=subprocess.PIPE)
              print(f"âœ… Success! Output: {os.path.join(OUTPUT_DIR, OUTPUT_FILE)}")
          except subprocess.CalledProcessError as e:
              print(f"âŒ Final render failed: {e.stderr.decode()}")
              sys.exit(1)
          
          EOF

      - name: Run animated video generation
        run: python3 generate_video.py

      - name: Configure Git  
        run: |  
          git config --global user.name "intellect9"  
          git config --global user.email "intellectra9@outlook.com"  

      - name: Commit and push generated video  
        env:  
          GH_PAT: ${{ secrets.GH_PAT }}  
        run: |  
          git stash --include-untracked  
          git pull origin main --rebase || echo "No rebase needed"  
          git stash pop || true  

          git add Video/  
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")
          git commit -m "ğŸ¬ Generated video with BOLD captions: ${timestamp}" || echo "No changes to commit"  

          git remote set-url origin "https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git"
          git push origin HEAD:main
          exit 0
