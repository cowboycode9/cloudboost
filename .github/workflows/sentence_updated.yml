name: Sentence Level Transcription (FIXED)

on:
  workflow_run:
    workflows: ["Transcript"]
    types:
      - completed
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - 'Visuals/**'
      - 'Trans/**'

permissions:
  contents: write

jobs:
  generate-transcription:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name != 'workflow_run' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Generate sentence-level transcription (FIXED)
        run: |
          python3 << 'EOF'
          import json, os, re
          from datetime import datetime
          from difflib import SequenceMatcher

          def clean(text):
              text = re.sub(r"[^\w\s]", "", text.lower())
              contractions = {
                  "dont": "do not",
                  "cant": "cannot",
                  "hes": "he is",
                  "im": "i am",
                  "youre": "you are",
                  "theyre": "they are"
              }
              return " ".join(contractions.get(w, w) for w in text.split())

          def similarity(a, b):
              return SequenceMatcher(None, clean(a), clean(b)).ratio()

          def main():
              trans_path = "Trans/transcription.json"
              visuals_path = "Visuals/visuals.json"

              if not os.path.exists(trans_path) or not os.path.exists(visuals_path):
                  print("❌ Missing input files")
                  return

              with open(trans_path, "r", encoding="utf-8") as f:
                  segments = json.load(f).get("segments", [])

              with open(visuals_path, "r", encoding="utf-8") as f:
                  visuals = json.load(f)

              results = []
              last_seg_idx = 0
              last_end_time = 0.0

              for item in visuals:
                  target = item["sentence"]
                  best_match = None
                  best_idx = None
                  best_score = 0.6  # SAFE threshold

                  search_limit = min(last_seg_idx + 25, len(segments))

                  for i in range(last_seg_idx, search_limit):
                      seg = segments[i]
                      score = similarity(target, seg["text"])

                      if score > best_score and seg["start"] >= last_end_time:
                          best_score = score
                          best_match = seg
                          best_idx = i

                  if best_match:
                      start = round(best_match["start"], 3)
                      end = round(best_match["end"], 3)

                      # Enforce monotonic time
                      if start < last_end_time:
                          start = round(last_end_time + 0.01, 3)
                          end = round(start + 0.5, 3)

                      last_seg_idx = best_idx + 1
                  else:
                      # Ghost sentence (not spoken)
                      start = round(last_end_time + 0.01, 3)
                      end = round(start + 0.5, 3)

                  duration = round(end - start, 3)

                  results.append({
                      "id": f"i{item['number']}",
                      "number": item["number"],
                      "sentence": target,
                      "start": start,
                      "end": end,
                      "duration": duration
                  })

                  last_end_time = end

              output = {
                  "metadata": {
                      "created_at": datetime.utcnow().isoformat() + "Z",
                      "total_sentences": len(results),
                      "source_files": {
                          "visuals": visuals_path,
                          "transcription": trans_path
                      }
                  },
                  "sentence_transcriptions": results
              }

              os.makedirs("Edits", exist_ok=True)
              with open("Edits/edit.json", "w", encoding="utf-8") as f:
                  json.dump(output, f, indent=2, ensure_ascii=False)

              print("✅ edit.json generated correctly")

          if __name__ == "__main__":
              main()
          EOF

      - name: Configure Git
        run: |
          git config --global user.name "intellectra9"
          git config --global user.email "intellectra9@outlook.com"

      - name: Commit and push edit.json
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          git stash --include-untracked
          git pull origin main --rebase || true
          git stash pop || true
          git add Edits/edit.json
          git commit -m "✅ Fixed sentence alignment for edit.json" || true
          git push https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git HEAD:main
