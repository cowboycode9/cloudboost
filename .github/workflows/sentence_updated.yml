name: Sentence Level Transcription

on:
  workflow_run:
    workflows: ["Transcript"]
    types: [completed]
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - 'Visuals/**'
      - 'Trans/**'

permissions:
  contents: write

jobs:
  generate-transcription:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name != 'workflow_run' }}

    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Generate sentence-level transcription
        run: |
          python3 << 'EOF'
          import json, os, re
          from datetime import datetime

          def clean(text):
              return re.sub(r"[^\w\s]", "", text.lower()).split()

          def flatten_words(segments):
              words = []
              for seg in segments:
                  for w in seg.get("words", []):
                      words.append({
                          "word": clean(w["word"])[0] if clean(w["word"]) else "",
                          "start": w["start"],
                          "end": w["end"]
                      })
              return words

          def find_sentence_span(sentence, words, start_idx):
              target = clean(sentence)
              if not target:
                  return None, None, start_idx explaining
              i = start_idx
              matched = []

              while i < len(words):
                  if words[i]["word"] == target[0]:
                      j = i
                      k = 0
                      temp = []
                      while j < len(words) and k < len(target):
                          if words[j]["word"] == target[k]:
                              temp.append(j)
                              k += 1
                          j += 1
                      if k == len(target):
                          return (
                              words[temp[0]]["start"],
                              words[temp[-1]]["end"],
                              temp[-1] + 1
                          )
                  i += 1
              return None, None, start_idx

          trans = json.load(open("Trans/transcription.json", encoding="utf-8"))
          visuals = json.load(open("Visuals/visuals.json", encoding="utf-8"))

          words = flatten_words(trans["segments"])
          cursor = 0
          results = []

          for item in visuals:
              s = item["sentence"]
              start, end, cursor = find_sentence_span(s, words, cursor)

              if start is None:
                  start = results[-1]["end"] + 0.01 if results else 0.0
                  end = start + 0.5

              results.append({
                  "id": f"i{item['number']}",
                  "number": item["number"],
                  "sentence": s,
                  "start": round(start, 3),
                  "end": round(end, 3),
                  "duration": round(end - start, 3)
              })

          output = {
              "metadata": {
                  "created_at": datetime.utcnow().isoformat() + "Z",
                  "total_sentences": len(results)
              },
              "sentence_transcriptions": results
          }

          os.makedirs("Edits", exist_ok=True)
          json.dump(output, open("Edits/edit.json", "w", encoding="utf-8"), indent=2, ensure_ascii=False)
          print("✅ Sentence timestamps synced perfectly")
          EOF

      - run: |
          git config --global user.name "intellectra9"
          git config --global user.email "intellectra9@outlook.com"

      - env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          git add Edits/edit.json
          git commit -m "✅ Exact word-level sentence timestamp fix"
          git push https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git HEAD:main
