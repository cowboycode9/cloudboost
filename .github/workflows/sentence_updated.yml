name: Sentence Level Transcription

on:
  workflow_run:
    workflows: ["Transcript"]
    types:
      - completed
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - 'Visuals/**'
      - 'Trans/**'

permissions:
  contents: write

jobs:
  generate-transcription:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name != 'workflow_run' }}

    steps:  
      - name: Checkout repository  
        uses: actions/checkout@v3  

      - name: Set up Python  
        uses: actions/setup-python@v4  
        with:  
          python-version: '3.10'  

      - name: Generate sentence-level transcription  
        run: |  
          python3 - << 'PYTHON_SCRIPT_END'
          import json
          import os
          import re
          from datetime import datetime
          from difflib import SequenceMatcher

          def normalize(text):
              """Strips everything but lowercase letters and numbers for universal matching."""
              if not text: return ""
              return re.sub(r"[^a-z0-9]", '', text.lower())

          def get_sim(a, b):
              return SequenceMatcher(None, a, b).ratio()

          def main():
              trans_p = "Trans/transcription.json"
              vis_p = "Visuals/visuals.json"
              
              if not os.path.exists(trans_p) or not os.path.exists(vis_p):
                  print(f"File missing: {trans_p} or {vis_p}")
                  return

              with open(trans_p, 'r') as f: trans_data = json.load(f)
              with open(vis_p, 'r') as f: visuals = json.load(f)

              # Flatten transcript into individual words
              words_db = []
              for seg in trans_data.get("segments", []):
                  for w in seg.get("words", []):
                      words_db.append({
                          "raw": w["word"],
                          "norm": normalize(w["word"]),
                          "start": w["start"],
                          "end": w["end"]
                      })

              results = []
              db_ptr = 0
              last_time = 0.0

              for item in visuals:
                  orig_sent = item.get("sentence", "")
                  # Split target into normalized words
                  target_words = [normalize(w) for w in orig_sent.split() if normalize(w)]
                  target_norm = "".join(target_words)
                  
                  if not target_norm: continue

                  best_match = None
                  high_score = 0.0
                  
                  # Lookahead window: Search up to 50 words ahead from current position
                  # This makes it universal for short or long sentences
                  search_range = min(db_ptr + 50, len(words_db))
                  
                  for start_i in range(db_ptr, search_range):
                      # Check various lengths around the expected word count
                      for length in range(max(1, len(target_words)-3), len(target_words)+6):
                          end_i = start_i + length
                          if end_i > len(words_db): break
                          
                          candidate_norm = "".join([words_db[k]["norm"] for k in range(start_i, end_i)])
                          score = get_sim(target_norm, candidate_norm)
                          
                          if score > high_score:
                              high_score = score
                              best_match = (start_i, end_i)
                          if score > 0.95: break # Optimization: Good enough

                  if high_score > 0.4 and best_match:
                      s_idx, e_idx = best_match
                      s_time = words_db[s_idx]["start"]
                      e_time = words_db[e_idx-1]["end"]
                      
                      results.append({
                          "id": f"i{item['number']}",
                          "number": item["number"],
                          "sentence": orig_sent,
                          "start": round(s_time, 3),
                          "end": round(e_time, 3),
                          "duration": round(e_time - s_time, 3)
                      })
                      db_ptr = e_idx
                      last_time = e_time
                  else:
                      # Universal fallback: If audio doesn't match, give it a 1s buffer
                      s_time = round(last_time + 0.01, 3)
                      e_time = round(s_time + 1.0, 3)
                      results.append({
                          "id": f"i{item['number']}",
                          "number": item["number"],
                          "sentence": orig_sent,
                          "start": s_time,
                          "end": e_time,
                          "duration": 1.0
                      })
                      last_time = e_time

              output = {
                  "metadata": {
                      "created_at": datetime.utcnow().isoformat() + "Z",
                      "total": len(results)
                  },
                  "sentence_transcriptions": results
              }

              os.makedirs("Edits", exist_ok=True)
              with open("Edits/edit.json", "w") as f:
                  json.dump(output, f, indent=2)
              print(f"Processed {len(results)} sentences successfully.")

          if __name__ == "__main__":
              main()
          PYTHON_SCRIPT_END

      - name: Configure Git  
        run: |  
          git config --global user.name "intellectra9"  
          git config --global user.email "intellectra9@outlook.com"  

      - name: Commit and push transcription file  
        env:  
          GH_PAT: ${{ secrets.GH_PAT }}  
        run: |  
          git stash --include-untracked  
          git pull origin main --rebase || echo "No rebase needed"  
          git stash pop || true  
          git add Edits/edit.json  
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")  
          git commit -m "ðŸ”„ Universal Word-Level Sync: ${timestamp}" || echo "No changes"  
          git push https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}.git HEAD:main


