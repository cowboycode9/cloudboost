name: Sentence Timestamp Alignment

on:
  workflow_run:
    workflows: ["Transcript"]
    types:
      - completed
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - 'Visuals/**'
      - 'Trans/**'

permissions:
  contents: write

jobs:
  generate-timestamps:
    name: Align Sentences and Update Edits
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name != 'workflow_run' }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Ensure full history for git operations

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Execute Alignment Script
        id: aligner
        run: |
          python3 -c "
          import json
          import os
          import re
          import sys
          from datetime import datetime, timezone

          # --- CONFIGURATION ---
          TRANSCRIPT_PATH = 'Trans/transcription.json'
          VISUALS_PATH = 'Visuals/visuals.json'
          OUTPUT_PATH = 'Edits/edit.json'
          
          # Ensure output directory exists
          os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)

          def normalize(text):
              if not text: return \"\"
              # Remove everything except alphanumeric and spaces
              return re.sub(r'[^\w\s]', '', text).lower().strip()

          def load_transcription_words(path):
              if not os.path.exists(path):
                  print(f'Error: {path} not found.')
                  sys.exit(1)
              
              with open(path, 'r') as f:
                  data = json.load(f)
              
              flat_words = []
              segments = data.get('segments', [])
              if not segments and isinstance(data, list):
                  segments = data
                  
              for segment in segments:
                  if 'words' in segment:
                      for w in segment['words']:
                          if 'word' in w and 'start' in w and 'end' in w:
                              flat_words.append({
                                  'text': normalize(w['word']),
                                  'start': float(w['start']),
                                  'end': float(w['end'])
                              })
              
              print(f'Loaded {len(flat_words)} words from transcription.')
              return flat_words

          def load_visuals(path):
              if not os.path.exists(path):
                  print(f'Error: {path} not found.')
                  sys.exit(1)
              with open(path, 'r') as f:
                  return json.load(f)

          def main():
              print('Starting alignment process...')
              all_words = load_transcription_words(TRANSCRIPT_PATH)
              visual_sentences = load_visuals(VISUALS_PATH)
              
              aligned_sentences = []
              db_ptr = 0
              last_sentence_end_time = 0.0

              for idx, item in enumerate(visual_sentences):
                  sentence_text = item.get('sentence', '')
                  sentence_norm = normalize(sentence_text)
                  sentence_words = sentence_norm.split()
                  scene_number = item.get('number', idx + 1)
                  
                  start_time = last_sentence_end_time
                  end_time = start_time + 2.0 
                  
                  if not sentence_words:
                      end_time = start_time + 0.5
                  elif db_ptr < len(all_words):
                      start_match_idx = -1
                      search_limit = min(len(all_words), db_ptr + 500) 
                      target_start_word = sentence_words[0]
                      
                      for i in range(db_ptr, search_limit):
                          if all_words[i]['text'] == target_start_word:
                              start_match_idx = i
                              break
                      
                      if start_match_idx != -1:
                          target_end_word = sentence_words[-1]
                          end_match_idx = -1
                          sub_search_limit = min(len(all_words), start_match_idx + len(sentence_words) + 20)
                          
                          for i in range(start_match_idx, sub_search_limit):
                              if all_words[i]['text'] == target_end_word:
                                  end_match_idx = i
                          
                          if end_match_idx != -1:
                              raw_start = all_words[start_match_idx]['start']
                              raw_end = all_words[end_match_idx]['end']
                              
                              if raw_start < last_sentence_end_time:
                                  raw_start = last_sentence_end_time
                              if raw_end <= raw_start:
                                  raw_end = raw_start + 0.5
                                  
                              start_time = raw_start
                              end_time = raw_end
                              db_ptr = end_match_idx + 1

                  if start_time < last_sentence_end_time:
                      start_time = last_sentence_end_time
                  
                  duration = round(end_time - start_time, 3)
                  
                  aligned_sentences.append({
                      \"id\": f\"i{idx+1}\",
                      \"number\": scene_number,
                      \"sentence\": sentence_text,
                      \"start\": round(start_time, 3),
                      \"end\": round(end_time, 3),
                      \"duration\": duration
                  })
                  last_sentence_end_time = end_time

              final_output = {
                  \"metadata\": {
                      \"created_at\": datetime.now(timezone.utc).isoformat(),
                      \"total\": len(aligned_sentences)
                  },
                  \"sentence_transcriptions\": aligned_sentences
              }
              
              print(f'Generated alignment for {len(aligned_sentences)} sentences.')
              with open(OUTPUT_PATH, 'w') as f:
                  json.dump(final_output, f, indent=2)
          
          if __name__ == '__main__':
              main()
          "

      - name: Commit and push transcription file
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
          REPO: ${{ github.repository }}
        run: |
          # Git Config
          git config --global user.name "intellectra9"
          git config --global user.email "intellectra9@outlook.com"
          git config --global --add safe.directory "$GITHUB_WORKSPACE"

          # Safety Sync: Stash local changes, pull latest remote, pop stash
          git stash --include-untracked
          git pull origin main --rebase || echo "No rebase needed - origin likely empty or consistent"
          git stash pop || true

          # Stage file
          git add Edits/edit.json

          # Check for changes
          if git diff --cached --quiet; then
            echo "No changes detected. Skipping commit."
            exit 0
          fi

          # Commit with Timestamp
          timestamp=$(TZ="Asia/Kolkata" date +"%Y-%m-%d %H:%M:%S IST")
          git commit -m "ðŸŽ¯ Improved Sync: ${timestamp}"

          # Push using Environment Variables (SAFE)
          git push https://x-access-token:${GH_PAT}@github.com/${REPO}.git HEAD:main
